{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "%matplotlib nbagg\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import dynet\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/en.pos.train'\n",
    "sentences = open(data_path, 'r').read().strip().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count, tags = defaultdict(int), set()\n",
    "for sentence in sentences:\n",
    "    lines = sentence.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        word, tag = line.strip().split('\\t')\n",
    "        word_count[word] += 1\n",
    "        tags.add(tag)\n",
    "tags = list(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in word_count.keys() if word_count[word]>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['<UNK>', '<s>', '</s>'] + words\n",
    "feat_tags = ['<s>'] + tags\n",
    "output_tags = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {word: i for i, word in enumerate(words)}\n",
    "feat_tags_dict = {tag: i for i, tag in enumerate(feat_tags)}\n",
    "output_tag_dict = {tag: i for i, tag in enumerate(output_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagid2tag_str(id):\n",
    "    return output_tags[id]\n",
    "\n",
    "def tag2id(tag):\n",
    "    return output_tag_dict[tag]\n",
    "\n",
    "def feat_tag2id(tag):\n",
    "    return feat_tags_dict[tag]\n",
    "\n",
    "def word2id(word):\n",
    "    return word_dict[word] if word in word_dict else word_dict['<UNK>']\n",
    "\n",
    "def num_words():\n",
    "    return len(words)\n",
    "\n",
    "def num_tag_feats():\n",
    "    return len(feat_tags)\n",
    "\n",
    "def num_tags():\n",
    "    return len(output_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = open(data_path, 'r').read().strip().split('\\n\\n')\n",
    "writer = open(data_path+'.data', 'w')\n",
    "\n",
    "for sen in sens:\n",
    "    lines = sen.strip().split('\\n')\n",
    "    ws, ts = ['<s>', '<s>'], ['<s>', '<s>']\n",
    "    for line in lines:\n",
    "        word, tag = line.strip().split()\n",
    "        ws.append(word)\n",
    "        ts.append(tag)\n",
    "    ws += ['</s>', '</s>']\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        feats = [ws[i], ws[i + 1], ws[i + 2], ws[i + 3], ws[i + 4], ts[i], ts[i + 1]]\n",
    "        label = ts[i + 2]\n",
    "        writer.write('\\t'.join(feats) + '\\t' + label + '\\n')\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "seed = 1008\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed_dim, pos_embed_dim = 100,100\n",
    "input_dim=5*word_embed_dim+2*pos_embed_dim\n",
    "hidden_dim,output_dim=200,len(feat_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist(u,v):\n",
    "    dist=torch.sum(u**2-v**2,dim=1)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eucl_POS_tagging(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(eucl_POS_tagging, self).__init__()\n",
    "        self.word_embeddings=nn.Embedding(len(words),word_embed_dim)\n",
    "        self.tag_embeddings=nn.Embedding(len(feat_tags),pos_embed_dim)\n",
    "        self.hidden1=torch.normal(torch.zeros(hidden_dim,word_embed_dim))\n",
    "        self.bias1=torch.normal(torch.zeros(1,hidden_dim))\n",
    "        self.hidden2=torch.normal(torch.zeros(hidden_dim,word_embed_dim))\n",
    "        self.bias2=torch.normal(torch.zeros(1,hidden_dim))\n",
    "        self.hidden3=torch.normal(torch.zeros(hidden_dim,word_embed_dim))\n",
    "        self.bias3=torch.normal(torch.zeros(1,hidden_dim))\n",
    "        self.hidden4=torch.normal(torch.zeros(hidden_dim,word_embed_dim))\n",
    "        self.bias4=torch.normal(torch.zeros(1,hidden_dim))\n",
    "        self.hidden5=torch.normal(torch.zeros(hidden_dim,word_embed_dim))\n",
    "        self.bias5=torch.normal(torch.zeros(1,hidden_dim))\n",
    "        self.hiddentag1=torch.normal(torch.zeros(hidden_dim,pos_embed_dim))\n",
    "        self.biastag1=torch.normal(torch.zeros(1,hidden_dim))\n",
    "        self.hiddentag2=torch.normal(torch.zeros(hidden_dim,pos_embed_dim))\n",
    "        self.biastag2=torch.normal(torch.zeros(1,hidden_dim))\n",
    "        self.network=torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "       \n",
    "    def forward(self, features):\n",
    "        word_ids = torch.tensor([word2id(word_feat) for word_feat in features[0:5]], dtype=torch.long)\n",
    "        tag_ids = torch.tensor([feat_tag2id(tag_feat) for tag_feat in features[5:]],dtype=torch.long)\n",
    "        \"\"\"\n",
    "        hyp1=1-hyp_dist(self.word_embeddings(word_ids[0]).repeat(hidden_dim,1),self.hidden1)\n",
    "        hyp2 = 1-hyp_dist(self.word_embeddings(word_ids[1]).repeat(hidden_dim,1),self.hidden2)\n",
    "        hyp3 = 1-hyp_dist(self.word_embeddings(word_ids[2]).repeat(hidden_dim,1),self.hidden3)\n",
    "        hyp4 = 1-hyp_dist(self.word_embeddings(word_ids[3]).repeat(hidden_dim,1),self.hidden4)\n",
    "        hyp5 = 1-hyp_dist(self.word_embeddings(word_ids[4]).repeat(hidden_dim,1),self.hidden5)\n",
    "        hyptag1 = 1-hyp_dist(self.tag_embeddings(tag_ids[0]).repeat(hidden_dim,1),self.hiddentag1)\n",
    "        hyptag2 = 1-hyp_dist(self.tag_embeddings(tag_ids[1]).repeat(hidden_dim,1),self.hiddentag2)\n",
    "\n",
    "        \"\"\"\n",
    "        euc1 = F.relu(1-eucl_dist(self.word_embeddings(word_ids[0]).repeat(hidden_dim,1),self.hidden1)+self.bias1)\n",
    "        euc2 = F.relu(1-eucl_dist(self.word_embeddings(word_ids[1]).repeat(hidden_dim,1),self.hidden2)+self.bias2)\n",
    "        euc3 = F.relu(1-eucl_dist(self.word_embeddings(word_ids[2]).repeat(hidden_dim,1),self.hidden3)+self.bias3)\n",
    "        euc4 = F.relu(1-eucl_dist(self.word_embeddings(word_ids[3]).repeat(hidden_dim,1),self.hidden4)+self.bias4)\n",
    "        euc5 = F.relu(1-eucl_dist(self.word_embeddings(word_ids[4]).repeat(hidden_dim,1),self.hidden5)+self.bias5)\n",
    "        euctag1 = F.relu(1-eucl_dist(self.tag_embeddings(tag_ids[0]).repeat(hidden_dim,1),self.hiddentag1)+self.biastag1)\n",
    "        euctag2 = F.relu(1-eucl_dist(self.tag_embeddings(tag_ids[1]).repeat(hidden_dim,1),self.hiddentag2)+self.biastag2)\n",
    "    \n",
    "        euc_output=euc1+euc2+euc3+euc4+euc5+euctag1+euctag2\n",
    "        out=self.network(euc_output)\n",
    "        output=nn.functional.log_softmax(out,dim=1)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(data_path+'.data', 'r').read().strip().split('\\n')\n",
    "minibatch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,epochs,train_data):\n",
    "    model.train()\n",
    "    total_loss=torch.tensor([0.0])\n",
    "    random.shuffle(train_data)\n",
    "    loss_function=nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=1e-2)\n",
    "    \n",
    "    for epochs in range(epochs):\n",
    "         print('epoch:',epochs)\n",
    "        \n",
    "         for j,line in enumerate(train_data):\n",
    "            fields = line.strip().split('\\t')\n",
    "            features, label, gold_label = fields[:-1], fields[-1], tag2id(fields[-1])\n",
    "            result = model(features)\n",
    "            loss = loss_function(result, torch.tensor([gold_label], dtype=torch.long))\n",
    "            total_loss+=loss\n",
    "            if j % minibatch_size == 0:\n",
    "                minibatch_loss = total_loss / minibatch_size\n",
    "                optimizer.zero_grad()\n",
    "                minibatch_loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss=torch.tensor([0.0])\n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "    return result.detach()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= eucl_POS_tagging().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    model.populate(filename)\n",
    "\n",
    "def save(filename):\n",
    "    model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "train(model,5,train_data)\n",
    "print('finished training!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(model,ws):\n",
    "   # first putting two start symbols\n",
    "    ws = ['<s>', '<s>'] + ws + ['</s>', '</s>']\n",
    "    ts = ['<s>', '<s>']\n",
    "    with torch.no_grad():\n",
    "        for i in range(2, len(ws) - 2):\n",
    "            features = ws[i - 2:i + 3] + ts[i - 2:i]\n",
    "\n",
    "       # running forward\n",
    "            output = model(features)\n",
    "\n",
    "       # getting list value of the output\n",
    "\n",
    "       # getting best tag\n",
    "            best_tag_id = np.argmax(output)\n",
    "\n",
    "       # assigning the best tag\n",
    "            ts.append(tagid2tag_str(best_tag_id.item()))\n",
    "\n",
    "       # refresh dynet memory (computation graph)\n",
    "\n",
    "    return ts[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'data/en.pos.dev.raw'\n",
    "writer = open(test_file+'.output.eucl.dim100.square', 'w')\n",
    "for sentence in open(test_file, 'r'):\n",
    "    words = sentence.strip().split()\n",
    "    tags = decode(model, words)\n",
    "    output = [word + '\\t' + tag for word, tag in zip(words, tags)]\n",
    "    writer.write('\\n'.join(output) + '\\n\\n')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(w_test_file,data_file):\n",
    "    true=0\n",
    "    compare=open(data_file,'r')\n",
    "    l=[]\n",
    "    k=[]\n",
    "    for sentence1 in compare:\n",
    "        words1=sentence1.strip().split()\n",
    "        if len(words1)==2:\n",
    "            l.append(words1[1])\n",
    "    for sentence2 in open(w_test_file,'r'):\n",
    "        words2=sentence2.strip().split()\n",
    "        if len(words2)==2:\n",
    "            k.append(words2[1])\n",
    "    for i in range(len(l)):\n",
    "        if l[i]==k[i]:\n",
    "            true+=1\n",
    "    accuracy=true/len(l)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2692272401959885\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_test('data/en.pos.dev.raw.output.eucl.dim100.square','data/en.pos.dev'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
